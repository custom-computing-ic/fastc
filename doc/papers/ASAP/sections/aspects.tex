\section{Aspects}

Aspects are standalone modules that capture functional cross-cutting concerns
that are decoupled from the primary function a program. AspectJ~\cite{Kiczales:2001}, which is the standard language for Aspect-Oriented Programming (AOP),  captures program execution points (such as method calls), and allows new code to be executed before, after or in place of a particular execution point, through a run-time process called \emph{weaving}. The main motivation behind AspectJ in particular, and AOP in general, is to solve the modularization problem when dealing with multiple cross-cutting functional concerns.

The LARA aspect-oriented design-flow~\cite{Cardoso:Carvalho:Coutinho:Luk:Nobre:Diniz:Petrov:2012}, on the other hand, performs the weaving process at compile-time to satisfy non-functional concerns, such as to improve performance on a particular hardware platform. For this purpose, the LARA weaving process manipulates and transforms the application sources. These new generated sources (woven code) incorporate the functional elements of the original sources and non-functional elements captured by the LARA aspects.

In this paper, we combine the LARA aspect design-flow with MaxC dataflow designs. In particular, MaxC uses standard C99 syntax to capture dataflow computations while aspects specify decoupled optimization and transformation strategies that operate on MaxC descriptions. This makes the
functionality of the application easier to understand, more
maintainable and portable since it is no longer obscured by various
structural or algorithmic transformations or platform specific
optimizations.

In this paper, we distinguish four categories of aspects (Table~\ref{tbl:aspects}): \emph{system aspects}, \emph{exploration aspects}, \emph{implementation aspects} and
\emph{development aspects}, which we explain next.



\begin{table}[tp]
\caption{Types of Aspects}
\label{tbl:aspects}
\centering
\begin{tabular}{l|l|l}
\hline
\bf{Aspect Type} & \bf{Aspect Name} & \bf{Description} \\
\hline
\hline
\multirow{3}{*}{system} & \multirow{2}{*}{\blt hw/sw partitioning} & capture mapping between  \\
&   \multirow{2}{*}{\blt reconfiguration} & application modules and \\
 & & GPP/GPU/FPGA accelerators\\
\hline
\multirow{3}{*}{exploration} & \multirow{2}{*}{\blt metaheuristic} & generate multiple implemen- \\
 & \multirow{2}{*}{\blt parameterisation} & tations based on design  \\
 & & space exploration strategies \\
\hline
\multirow{2}{*}{implementation} &\blt operator optimisation &  capture low-level hardware \\
& \blt design configuration & optimisations  \\
\hline
\multirow{3}{*}{development} & \blt simulation & \multirow{2}{*}{improve developer}  \\
& \blt monitorisation & \multirow{2}{*}{productivity} \\
& \blt compilation &  \\
\hline
\end{tabular}
\end{table}

\subsection{System Aspects}

System aspects capture transformation or optimization strategies that
affect the whole application such as those concerning
hardware/software partitioning, or run-time reconfiguration
capabilities. The goal is to improve communication
between CPU and accelerator via hardware/software partitioning or
remove idle functions from the accelerator using run-time
reconfiguration.

As mentioned in the previous section, maxc functions can be embedded within the C application but cannot be invoked directly by software functions. Instead, a maxc pragma can be used on top of software functions definitions or C calls to indicate alternate hardware implementations. For instance, the following C code:

\noindent\texttt{\footnotesize\marktext{void maxc\_f() \{\emph{/* dataflow implementation */}\}} \\
void f() \{\emph{/* software implementation */}\} \\
\marktext{\#pragma maxc hw:maxc\_f} \\
f(); \\
}

\noindent indicates that the software implementation of f() can be mapped to the dataflow implementation described in maxc\_f(). This way, the maxcc compiler can automatically switch from software to hardware implementations.

Hence, a hardware/software partitioning strategy can be performed in five steps: (i)~detecting hotspots in the program, (ii)~detecting code patterns from hotspots that are suited for dataflow computation and acceleration, (iii)~performing the outlining transformation so that each candidate for acceleration is enclosed in a function $f$, (iv)~deriving a dataflow version $max\_f$ from state-based $f$, (v)~placing a maxc pragma on top of each function call to $f$ associating it to the corresponding $maxc\_f$ function. Each of these steps can be described as separate LARA aspect and combined to form a hardware/software partitioning strategy. For instance, the following aspect can be used to find potential hotspots for step (i):

\lstset{style=lara}
\begin{figure}[!h]
\begin{lstlisting}
aspectdef FindHotspots
select function.loop{is_innermost} end
apply
    $loop.insert before
       %{monitor_instanceI("[[$loop.key]]");}%;
    $loop.insert after
       %{monitor_instanceE("[[$loop.key]]");}%;
end

select function.loop{is_innermost}.entry end
apply $begin.insert after
       %{monitor_iterI("[[$loop.key]]");}%;
end
select function.loop{is_innermost}.exit end
apply $begin.insert before
       %{monitor_iterE("[[$loop.key]]");}%;
end
end
\end{lstlisting}
\caption{Aspect for identifying hot spots.}
\end{figure}

\noindent The above aspect automatically instruments any C application to self-monitor its innermost loops at run-time, as they are natural candidates for dataflow-based acceleration. In particular, this monitorization aspect can compute for every innermost loop: (a) the average number of times it has been executed, (b) the average number of iterations, (c) the loop average time, and (d) the loop iteration average time. For this purpose, we use a monitoring API composed by 4 functions to mark the beginning and end of the loop (monitor\_instanceI and monitor\_instanceE respectively), and to mark the beginning and end of an iteration (monitor\_iterI and monitor\_iterE respectively). These monitoring functions keep an account of the frequency of execution and the time to complete the whole loop and a single iteration.  The aspect code is as follows: Line~2 selects all loops in the application that are innermost (loops with no other loops enclosed); Lines~3--8 place an instance monitor call before and after each selected loop; Lines 10~13 select all entry points inside the loop and insert a monitoring call to mark the beginning of each iteration; Lines~14--17 place an instance monitor call to mark the end of each iteration. The following table shows an example of applying this aspect on a code containing a loop:

{\footnotesize
\fontfamily{pcr}\selectfont
\begin{tabular}{l|l}
\hline
\bf{original code} & \bf{woven code}  \\
\hline
\hline
void f() \{ & void f() \{ \\
%\hspace{3ex}$\ldots$         & \hspace{3ex}$\ldots$ \\
                             & \hspace{3ex}\marktext{monitor\_instanceI("f:1");} \\
\hspace{3ex}while (i < N) \{ & \hspace{3ex}while (i < N) \{ \\
                             & \hspace{6ex}\marktext{monitor\_iterI("f:1");} \\
\hspace{6ex}i++;             & \hspace{6ex}i++; \\
                             & \hspace{6ex}\marktext{monitor\_iterE("f:1");} \\
\hspace{3ex}\}               & \hspace{3ex}\} \\
                             & \hspace{3ex}\marktext{monitor\_instanceE("f:1");} \\
%\hspace{3ex}$\ldots$         & \hspace{3ex}$\ldots$ \\
\hline
\end{tabular}
}
\vspace{2ex}

\noindent It can be seen in the woven code that each monitoring call receives as a parameter the loop key, which uniquely identifies the loop within the application. The loop key concatenates the function name with the position of the loop within the abstract syntax tree. For instance, \emph{f:2:1} corresponds to the 1st loop inside the 2nd outermost loop of function $f$. The hotspots can be identified by an aspect (not shown) that takes the profiling information generated by the monitorization API calls, and uses an heuristic to compute the most profitable computations to be offloaded to hardware.

To support runtime reconfiguration, we specify the configuration associated with the function call in the maxc pragma. For instance:

\noindent\texttt{\footnotesize{\marktext{\#pragma maxc hw:maxc\_f0 cfg:c0}\\
x = f(0); \\
\marktext{\#pragma maxc hw:maxc\_f1 cfg:c1}\\
y = f(x); \\
\marktext{\#pragma maxc hw:maxc\_g cfg:c1}\\
z = g(x); \\
}}

\noindent With the above code annotations, the maxcc compiler can generate multiple configurations, each containing  a number of MaxC function implementations that can be executed in parallel. If the configuration name is not specified using the MaxC pragma, then the maxcc compiler assumes a default configuration. Having a single configuration can lead to situations where at any point in time and due to data dependencies, part of the functions are idle. With run-time reconfiguration, we can exploit unused resources to support active functions. In particular, during the execution of an application, we select various configurations at different points in time to maximize the utilization of FPGA resources. Within this context, we define a valid partition as a set of configurations that allows the system to complete an application. In the above example, configuration c0 contains a single implementation for f (\emph{maxc\_f0}), and thus could use more resources and be potentially faster than the \emph{maxc\_f1} version which must share configuration \emph{c1} with \emph{maxc\_g}.

The work in~\cite{Xinyu:Qiwei:Luk:Qiang:Pell:2012} proposes an
approach for extracting valid and efficient partitions. To realize
runtime reconfiguration with maxcc, and experiment the effects of
multiple partitions without modifying the original sources, we use the
aspect shown in Figure \ref{fig:aspect-reconf}.  The input to the
aspect is a partition (lines 2--4). The partition is implemented as a
hash table that maps a function call (key) to a hardware
implementation, represented as tuple containing the hardware
implementation name (hw) and the configuration name (cfg).

\lstset{style=lara}
\begin{figure}[!h]
\begin{lstlisting}
aspectdef ReconfigAspect
input
   partition
end
select function.call end
apply
   if ($call.key in partition) {
      var cfg = partition[$call.key].cfg;
      var hw = partition[$call.key].hw;
      $call.insert before %{
         #pragma maxc hw:[[hw]] cfg:[[cfg]]
      }%;
   }
end
end
\end{lstlisting}
\caption{Reconfiguration aspect.}
\label{fig:aspect-reconf}
\end{figure}

Table \ref{fig:aspect-hash} shows an example of a hash table whose key
uniquely identifies a function call in the application. The key
(e.g. main:f:1) is formed by concatenating the name of the caller
function (main), the name of the invoked function (e.g. f) and a
counter (1).  Line~5 in the aspect above selects all function calls,
and for each call found in the partition (line~7), we set the
appropriate pragma on top of the invocation (lines 10--12).
%{\footnotesize
%\fontfamily{pcr}\selectfont
\begin{table}[!h]
\caption{Hash table for the reconfiguration aspect.}
\label{fig:aspect-hash}
\centering
\begin{tabular}{c|c|c}
\hline
\multicolumn{3}{c}{\bf{partition}} \\
\hline
\bf{\$call.key} & \bf{hw} & \bf{cfg}  \\
\hline
main:f:1 & maxc\_f0 & c0 \\
main:f:2 & maxc\_f1 & c1 \\
main:g:3 & maxc\_g & c1 \\
\hline
\end{tabular}
\end{table}
%}



\subsection{Exploration Aspects}

Exploration aspects deal with strategies that generate multiple
designs based on parametrisation and can act on any level of the
design flow (C code, C and MaxC, or MaxC design). They enable
systematic exploration of trade-offs and optimisation
opportunities. An example LARA aspect for design space exploration is
shown in Figure \ref{fig:aspect-exploration}. It highlights the feedback capabilities of the design
flow: the aspect will generate and build the MaxC designs until the
resource usage passes a specified LUT threshold, at each step
increasing the parallelism of the design (by replicating the
computational pipeline).
% For instance, we can generate

\lstset{style=lara}
\begin{figure}[!h]
\begin{lstlisting}
  aspectdef DSEStrategy
  var config = { 'Dsp_factor': 1,
    'Exponent'  : 8,
    'Mantissa'  : 24 };
  var par = 0, lut_threshold = 10000;
  do {
    par++;
    config['Par'] = par;
    var designName = genName(config);
    call genMaxC(designName, config);
    buildMaxC(designName);
  } while (@hw[designName].lut < lut_threshold);
  end
\end{lstlisting}
\caption{Aspect for increasing design parallelism subject to a LUT
  threshold.}
\label{fig:aspect-exploration}
\end{figure}

\subsection{Implementation Aspects}

Design aspects capture low level design optimizations that can be
applied to the MaxC designs in order to improve timing or explore
various resource usage trade-offs.

Aspects can be used to enable design space exploration of resource
usage vs. accuracy trade-offs by varying the word
lengths. Alternatively we can use them to explore resource trade-offs
by mapping computation to specialised FPGA blocks. For example, the
aspect in Figure \ref{fig:aspect-DSP} can be used to map arithmetic
expressions to DSP blocks. We define the DSP balance factor to be used
(none, normal, full), the granularity (which decides if we break up
arithmetic expressions to insert DSP Factors between them) and the
number of independent applications.

\lstset{style=lara}
\begin{figure}[!h]
  \centering
  \begin{lstlisting}
aspectdef dspFactor
var op_granularity =
 [{DspFactor: 'full', MultiplyOp: 20, AddOp: 5 },
  {DspFactor: 'normal', MultiplyOp: 3}];

select function.statement end
apply
   for (var i in op_granularity) {
      var gprofile = op_granularity[i];
      var match = true;
      for (var k in gprofile) {
         if (k != 'DspFactor') {
            match &= ($statement.num_construct(k)
                      >= gprofile[k]);}}
      if (match) {
         var pragma = '#pragma maxc balanceDSP:'
                      + gprofile.DspFactor;
         $statement.insert before "[[pragma]]";
         break;}}
   end
end
  \end{lstlisting}
  \caption{Aspect for exploring mapping of computation to DSP blocks.}
  \label{fig:aspect-DSP}
\end{figure}

Aspects steps:

\begin{enumerate}
\item Identify arithmetic expressions;
\item Split them according to granularity;
\item Insert annotation to adjust DSP usage;
\item Repeat for a given number of applications.
\end{enumerate}

\begin{figure}
  \begin{lstlisting}
    #pragma balanceDSP=full
    int result = p[0]  * c_0_0_0;
    int result = result + p[1]  * c_p_0_0;
    #pragma balanceDSP=full
    int result = result + p[-1] * c_n_0_0;
  \end{lstlisting}
  \caption{One possible result of applying
    \texttt{OptimizeDSPUsage(full, fine, 2)} to Lines 13 -- 17 of Figure
    \ref{fig:maxc-1dconv}.}
  \label{fig:maxc-1dconv-aspect}
\end{figure}

Figure \ref{fig:maxc-1dconv-aspect} shows one of the possible results
of applying the aspect \texttt{OptimizeDSPUsage(full, fine, 2 } to
Lines 13 -- 17 of Figure \ref{fig:maxc-1dconv}.

Using LARA we can implement and combine these aspects to enable
systematic design space exploration of all the optimisations options
exposed by the MaxC backend resulting in the generation of a large
number of designs. The feedback-directed compilation process of LARA can
be used to capture and extract feedback from the backend reports
pertaining to resource usage or timing information and automatically
adjust the compilation process.

\subsection{Development Aspects}

Development aspects capture transformations that have an impact on the
development process such as debugging, simulating kernels or improving
compilation speed. Separating these concerns makes the original
application code easier to maintain and enables the automatic
application of these transformations to a wide range of designs, thus
improving developer productivity.

\subsubsection{Simulation Aspects}

The goal for the MaxC kernel simulation model is that it should be
possible to compile and run dataflow designs using the standard GCC
toolchain in order to verify the logical correctness of the
design. However, this often leads to the need of adding boilerplate
code that would otherwise not be required by the MaxC backend, just to
enable simulation. Since this process is itself manual and hence
error-prone it defeats the very purpose of testing the design. One
approach would be to require users to always use the simulation
API. However this unnecessarily complicates the dataflow design. Our
solution is to use separate aspects to generate the simulation
designs.

Simulation aspects can be applied to the original dataflow design to
enable pure software simulation. This approach gives more freedom when
designing MaxC constructs -- since we are not necessarily concerned
weather they compile using the standard GCC toolchain. This in turn
allows us to provide a neater syntax but also hides and automates the
details of generating simulation designs from the developer.

Aspect steps:

\begin{enumerate}

\item insert kernel simulation loop in hostcode %(Figure )
  \begin{figure}[!h]
    \begin{lstlisting}
      for (int i = 0 ; i < CYCLE_COUNT; i++) {
        kernel_Convolution1d(p, out, 2);
        update_stream_pointers(p, out);
      }
    \end{lstlisting}
    %\caption{Stream simulation loop.}
    %\label{fig:maxc-simulation}
  \end{figure}

\item insert boilerplate code in the dataflow design to enable simulation.
  % The result of applying the simulation aspect to the dataflow in
  %  Figure \ref{fig:maxc-1dconv} is shown in Figure
  %  \ref{fig:maxc-sim-aspect}.
  For example any stream and counter used in the kernel body need to
  be declared using special calls that also pass in unique identifiers
  which are used to store and retrieve the values at each cycle in a
  separate data structure (e.g. \texttt{`stream\_init\_i(int
    stream\_id)}). On each kernel cycle, the function then either
  allocates a new stream or increments the stream pointer if the
  stream has already been allocated.
  \begin{comment}
    \begin{figure}[!h]
      \begin{lstlisting}
        float* i4 = count_i(1000, 1, 0);
        float* i1 = countChain_i(n1, 1, i4, 0);
      \end{lstlisting}
      \caption{Applying the simulation aspect to the dataflow design in
        Figure \ref{fig:maxc-1dconv}}
      \label{fig:maxc-sim-aspect}
    \end{figure}
  \end{comment}

\end{enumerate}

\lstset{style=MaxC}


\subsubsection{Debug Aspects}

Because the current execution model does not provide runtime debugging
of hardware designs, the easiest solution to debug designs is to log
the values of various streams during execution. The insertion of debug
statements can be encapsulated in aspects. It is particularly
important to separate debug aspects from the original application code
since debug blocks can influence the compilation time and timing
constraints as well as the behaviour of the design.

\lstset{style=lara}
\begin{figure}[!h]
  \centering
\begin{lstlisting}
aspectdef DebugValues

select function.vref end
apply
   $vref.parent_stmt.insert before
    %{ log("[[$vref.name]]", [[$vref.name]]); }%
   $vref.parent_stmt.insert after
    %{ log("[[$vref.name]]", [[$vref.name]]); }%
end
condition $vref.is_out end

end
\end{lstlisting}
  \caption{Aspect for automatically inserting debug blocks.}
  \label{fig:aspect-debug}
\end{figure}

\subsubsection{Compilation Aspects}

Compilation aspects can be applied during the development process to
create versions of the dataflow design that compile faster. They apply
changes such as reducing the operating frequency, removing debug
blocks or applying design-level optimizations that can resolve timing
constraints. Naturally reducing the compilation time increases
developer productivity.

Different compilation aspects can be used to build in parallel more
versions of the application that allow incremental testing (in order
of compilation times):
\begin{enumerate}
\item Fastest design to build will be a naive version, optimized for
  compile time (minimum design and memory frequency, disabled debug
  blocks, no arithmetic optimizations). This allows verifying
  application correctness;
\item The debug version (enabled debug blocks) is built in parallel to
  allow debugging of errors identified in the previous step;
\item Finally a version optimized for performance (maximum frequency,
  no debug block, arithmetic optimisations) is compiled to allow
  testing of non-functional requirement.
\end{enumerate}
