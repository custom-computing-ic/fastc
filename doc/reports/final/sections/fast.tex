\chapter{The \FAST{} Language}
\label{sec:fast}

\FAST{} (Facile Aspect-driven Source Transformation) is a novel
language for specifying dataflow designs that are used as a starting
point for the design flow proposed in Section
\ref{sec:design-flow}. In particular, we use C syntax to capture
dataflow computations, and, instead of heavily relying on API
libraries to specify the design (as in MaxCompiler \cite{5719584} or
Streams-C \cite{Gokhale:Stone:Arnold:Kalinowski:2000}), we use aspects
to implement the transformations required for the actual
implementation.  In this section we outline the design goals of the
language, introduce an early prototype and examine its advantages and
limitations and propose an enhanced version. We highlight the main
features of \FAST{} and explain how these translate to components of
dataflow designs. We analyse the major challenges we met in creating
the \FAST{} language and highlight the strategies we adopted for
overcoming them.

\section{Design Goals}

\FAST{} provides the following features that are
required by the proposed flow:

\begin{itemize}
\item \emph{Imperative specification of dataflow designs}. C99 syntax
  is enforced by the \FAST{} compiler which is based on the ROSE
  Framework~\cite{Quinlan:2000}. The familiar syntax makes the
  language easy to adopt thus facilitating translation of existing
  implementations to dataflow designs.
\item \emph{Good integration with existing source level translation and
    weaving tools}. Simple syntax allows the language to interact well
  with existing compilers or source to source translation frameworks,
  allowing source level optimisations to be applied through different
  tools.
\item \emph{Combined hardware/software design}. Specifications of dataflow
  kernels and CPU run-time software can be mixed. The example shown in
  Listing \ref{lst:fast-bscholesp} can be compiled with the GCC toolchain,
  but when using the \FAST{} compiler, the pragma indicates the link
  between the software and hardware, which results in an accelerated
  hardware/software solution.
\item \emph{Support for data path and control path generation}. \FAST{}
  allows specifying both data and control operations that are
  automatically mapped to stream multiplexers.
\end{itemize}

\FAST{} is used to express the simplest form of a dataflow design
while optimisations and other transformations are encapsulated in
aspects which are developed separately and applied through aspect
weaving. This results in a flexible approach for generating and
exploring the space of efficient dataflow designs.

Designs in \FAST{} are compiled to MaxCompiler designs composed of
inter-connected functional kernels. Communication between kernels is
asynchronous, so they can operate independently, and compute only when
all active inputs have available data.

\section{Features}

We originally developed a simple prototype of the FAST language
sufficient to support our application benchmark
(\Cref{sec:benchmark}). We then extended this prototype with more
advanced features (as described in \Cref{sec:fast-extensions}) which
were required to meet our design goals.

In this section we use a very simple implementation of a dataflow
kernel which is part of our Black Scholes benchmark to highlight some
of the main features of the \FAST{} language. This kernel simply
computes the result of the finite difference approximation solution to
the Black Scholes Equations, iterating both in space (the fast
dimension -- stock prices) and in time (the slow dimension). In
\Cref{sec:fast-ref} we analyse the same example in light of our
extensions described in \Cref{sec:fast-extensions} and argue that
these simplify the language.

\lstset{style=MaxC}

\begin{lstlisting}[
  label={lst:fast-bscholesp},
  caption={\FAST{} dataflow kernel for Black Scholes Options pricing}
  ]
  void Price_FPGA(s_float8_24 stockPrices,
                  float8_24 c1, float8_24 c2, float8_24 c3,
                  int32 nStocks, int32 stencilOrder, int timesteps)
  {
    // read input stream
    in(stockPrices);

    // counters for timestep and stockstep iteration
    int32 timestep  = count(timesteps, 1);
    int32 stockstep = countChain(nStocks, 1, i4);

    #pragma FAST DSPBalance:full
    s_float8_24 result =   stockPrices[ 0] * c1
                         + stockPrices[ 1] * c2
                         + stockPrices[-1] * c3;

    // boundary conditions for the stencil computation
    int32 up = (stockstep >= stencilOrder)
               && (stock < stockstep - stencilorder);

    // write output stream
    out(up ? result : stockPrices);
  }

  // Regular C style CPU implementation
  void Price_CPU(...) {...}

  int main() {
    #pragma FAST hw:Price_FPGA
    Price_CPU(...);
  }
\end{lstlisting}

Listing \ref{lst:fast-bscholesp} highlights some of the most important
features of a \FAST{} dataflow kernel:
\begin{itemize}
\item dataflow kernels are declared as regular C functions with inputs
  defined as arguments in the function signature;
\item streams are represented through \texttt{s\_<type>} types, which
  are type definitions for \texttt{<type *>}; these are interpreted
  as special types by the \fastc{} compiler;
\item to provide easy access to previous, current and future stream
  values array notation is used with positive offsets accessing future
  values and negative offsets accessing previous stream values
\item supported offset values are linear combinations of compile-time
  constants or variables (either loop induction variables,
  or normal variables but for which a compile time range of values is
  specified, as a requirement for generating efficient hardware)
\item constructs such as loops are supported as long as their bounds
  are known at compilation time and are used to parametrise dataflow
  designs.
\item C function calls are mapped to dataflow kernels via pragmas
  (Line 17) which provides the flexibility of selecting a particular
  dataflow configuration based on run-time conditions
\end{itemize}


Additionally and API is provided for higher-level constructs such as
I/O functions (\texttt{in()}, \texttt{out()}), counters
(Listing \ref{lst:fast-bscholesp}, Lines~4--5) and functions to multiplex
streams (\texttt{mux()}).

\Cref{table:maxc-features} summarises the features of \FAST{} and
shows that many features are implemented the using C99 style
syntax. Mathematical functions are specified using their standard C
library results in a more intuitive, easier to learn programming model
but complicates the mapping of \FAST{} designs to FPGA dataflow
designs. Another important consequence of maintaining compatibility
with C99 syntax is the ability to directly translate C applications to
dataflow designs.


\begin{table}[!h]
  \centering
  \renewcommand{\arraystretch}{1.5}
  \begin{tabularx}{\textwidth}{p{3.5cm}|X|X}
    \hline
    \bf{Feature}                   & \bf{Description}                   & \bf{Method (see Fig.~\ref{fig:maxc-1dconv})} \\
    \hline\hline
    \multirow{2}{*}{Input/Output}         & Declared in function header          & C99 (line 1)                                 \\\cline{2-3}       & \texttt{in()},\texttt{out()}  & \FAST{} API (lines 2,11) \\
    \hline
    \multirow{2}{*}{Control}     & Ternary op., \texttt{if} statement & C99 (line 11)                                \\\cline{2-3}      & Stream mux (\texttt{mux()})       & \FAST{} API  \\
    \hline
    \multirow{2}{*}{Computation} & +, *, /, -                         & C99 (line 8)                           \\\cline{2-3} & log, exp, sqrt, sin etc.  & \#include $<$math.h$>$  \\
    \hline
    \multirow{2}{*}{Streams}     & Declared as pointers               & C99 (line 1)                                 \\\cline{2-3}       & Accessed with array index & C99 (line 8) \\
    \hline
    Optimisation                 & C pragmas                   & C99 (line 7)                                 \\
    \hline
    Parameterization             & Constants, variables                   & C99                                          \\
    \hline
    Hardware \  Mapping                  & C pragmas                   & C99 (line 17)                                \\
  \end{tabularx}
  \caption{Summary of the main features of the \FAST{} language.}
  \label{table:maxc-features}
\end{table}

In the remainder of this section we provide an in-depth analysis of
these features and design challenges associated with capturing them in
a simple imperative language.

\subsection{Kernels and Streams}

Kernels represent a unit of computation that is mapped to the FPGA.
They are C functions that can be called directly (as below) or linked
via pragmas in C application code.

\begin{lstlisting}[caption={Simple \FAST{} dataflow kernel.}]
  // standard C main function
  int main() {
    int *x = ..., *y = ...;
    PassThrough(x, y);
    ...
  }

  #pragma fast
  void PassThrough_CPU(int32 *x, int *y) {
    in(x);
out(y);
  }
\end{lstlisting}

The kernel inputs can be streams or run-time constants. The kernel
produces as output one or more streams of data.

The example above shows a very simple kernel with two streams:

\begin{itemize}
\item output (write) stream "y" - allows access to previous and current values;
\item input (read) stream "x" - allows access to previous, current and future values;
\end{itemize}

The kernel Sum shown below computes the sum of input stream
x. CURRENT\_CYCLE is a special value defined by MaxC that holds the
value of the current kernel cycle.

\begin{lstlisting}[caption={\FAST{} kernel computing the sum of an input stream.}]
  #pragma maxc dataflow(y)
  void Sum(int *x, int *y) {
    if ( CURRENT_CYCLE == 0 )
    *y = x[0];
    else
    *y = y[-1] + x[0];
  }
\end{lstlisting}

All streams declared within a kernel are write streams.

The indices for stream offsets can be compile time values as in the
example above. When using run-time values, it can be more efficient
(in terms of FPGA resource utilization) to specify bounds for the
offset expressions. For example in the kernel shown below, the input
stream "offests" contains offsets at which to select elements from
input stream "x". We may, for example, know that our application is
only expect to use offsets smaller than 256, so we can provide this
optimisation hint to the compiler.

\begin{lstlisting}[caption={\FAST{} kernel using offsets.}]
  void Bounds(int *x, int *offsets, int *y) {
    int bounded_offset = make_offset(*offsets, 0, 256);
    *y = x[*offsets] * 2;
  }
\end{lstlisting}

\subsection{Inputs and Outputs}

In the examples above we declare inputs and outputs in the kernel
headers. Assigning to a declared output stream automatically outputs
the value. Assignments to input streams are illegal and an error is
indicated by the compiler.

\subsection{Control}

\subsubsection*{Conditionals}

Regular control statements can be used. When conditionals are based on
stream values, the control statement maps to hardware multiplexers
(e.g. in the Sum kernel above, if ( CURRENT\_CYCLE == 0 )).

\subsubsection*{Loops}

It is only possible to use loops statements (while, for) if their
bounds and induction variables are known at compile time. In the
ParallelSum kernel below the loop is used to replicate the computation
Par times.

\begin{lstlisting}[caption={Using loops for \FAST{} design parametrisation}]
  void ParallelSum(int *x[Par], int *Sum[Par]) {
    for (int i=0; i <Par; i++)
    sum[i][0] = sum[i-1][0] + x[i][0];
  }
\end{lstlisting}
\subsection{Computation}

\begin{itemize}

\item C arithmetic operators can be used as usual on stream values (not streams themselves).
\item Arithmetic on streams (equiv. to pointer arithmetic) is illegal.
\item C math.h function calls are automatically mapped to efficient hardware blocks.
  p
\end{itemize}

The example below computes the difference between the arithmetic and
geometric average of two consecutive elements in a streams (boundary
cases ignored).


\begin{lstlisting}
  void AvgDiff(int *x, int *y) {
    int arithmetic_avg = (x[0] + x[-1]) / 2;
    int geometric_avg  = (sqrt(x[0] * x[-1]);
    *y = geom - avg;
  }
\end{lstlisting}

\subsection{State}
State can be saved and subsequently accessed between kernel iterations
by use of global values as shown in the kernel CycleSum that adds the
current cycle count to the value of the input stream, and also updates
the cycle value before the next iteration
\begin{lstlisting}
  int cycle = 0;
  void CycleSum(int *x, int *y) {
    *y = *x + cycle;
    cycle++;
  }
\end{lstlisting}

\subsection{Pragmas}

Pragmas are used to indicate:
\begin{itemize}
\item the link between hardware and software
\item optimisation options exposed by the backend tools
\end{itemize}

This enables users to switch seamlessly between compilers and,
eventually backend compilers, contributing towards the Integration
requirement of our design flow.

However, unlike in other approaches pragmas are not
meant to be inserted manually -- although this is possible -- but
rather they are to be controlled by the corresponding aspect
descriptions (for hardware / software partitioning, optimisation
etc.). The use of pragmas enables aspect descriptions to operate
correctly (or rather to not operate incorrectly) accross various
platforms (since, by definition, compiler directives are simply
ignored if they are not understood by the compiler) and contributes
towards our Portability requirement.

Pragams in \FAST{} follow the syntax:

This facilitates...

\section{Extensions}

\label{sec:fast-extensions}

\subsection{Inferring Stream Type}

Instead of specifying inputs and outputs manually, the \fastc{}
compiler can be extended to automatically infer the type of streams
(read or write). This is based on the rules:
\begin{itemize}
\item If a stream is assigned to at least once then it is a write stream
\item If a stream is assigned to more than once, then this is an error
\item If a stream is declared in the kernel header and not written
  to, then it is a read stream
\item If a stream is declared within the body of the dataflow
  kernel, it is a read/write stream
\end{itemize}

Additionally casting between variable types can be inferred in some
instances by using type coercion.


\subsection{Multiple Kernel Support}

Some designs may require more than one dataflow kernel. This may
required for instance if one kernel is to perform operations
asynchronously from the other. A recurrent pattern is where a separate
kernel is used to generate the memory command stream, which contains
the addresses that are to be read from DRAM (\Cref{sec:fast-dram}).

To support this scenario, MaxCompiler uses the concept of a manager
which specifies how kernels are instantiated and connected together to
form a design \Cref{sec:back-maxcompiler}.

To support this scenario in FAST we extend our original pragma
notations to enable the specification of:
\begin{itemize}
\item correlation between input and output
\item kernel instances (how?)
\end{itemize}

Since this can result in a fairly long-winded
T

\subsection{Support Designs with DRAM}
\label{sec:fast-dram}

To support DRAM a dataflow design requires additional kernels that
generate memory commands asynchronously from the computational kernel.


\subsection{Run-time Reconfiguration Support}


To support run-time reconfiguration \fastc{} must know that
alternative partititions are to be generated for a function.
Additionally, boilerplate code for trigerring the run-time
reconfiguration needs to be added. This contains:
\begin{itemize}
\item code required to save current FPGA state -- this is required to
  prevent loss of data as a result of resetting the device as part of
  the run-time reconfiguration process
\item code on the CPU side to upload the new configuration
\item code on the CPU side to queue new input streams and start the
  computation
\end{itemize}



\section{Revised FAST Example}
\label{sec:fast-ref}

Listing \ref{lst:fast-bscholesr} shows the revised Black Scholes
implementation with the revised FAST language. No API calls are
required for the counters or state saving. Inputs and outputs are
clearly declared in the kernel header and the compiler can
automatically infer whether a parameter stream is input or output.

Additionally, we can use FPGA DRAM (bandwidth of 40GB/s) as the source
for data, not just PCI-Express (2GB/s) which is a major improvement in
terms of I/O bandwidth. This is achieved through our DRAM extensions
and the support for multiple kernel that allows us to fully specify a
three kernel design that implements the required pricing computation.

\lstset{style=MaxC}

\begin{lstlisting}[
  label={lst:fast-bscholesr},
  caption={\FAST{} dataflow kernel for European Options pricing}
  ]
  float i4 = 0;
  float i1 = 0;
  void Price_FPGA(
  float* p, float *r,
  float c_0_0_0, float c_p_0_0, float c_n_0_0,
  int n1, int ORDER)
  {

    i4 = i4 >= n1    ? 0 : i4 + 1;
    i1 = i1 >= 1000  ? 0 : i1 + 1;

    #pragma FAST DSPBalance:full
    int result =

    p[0]  * c_0_0_0 +
    p[1]  * c_p_0_0 +
    p[-1] * c_n_0_0;

    int up = (i1 >= ORDER) && (i1 < n1 - ORDER);
    r = up ? result : p;
  }

  void Price_CPU(...) {...}

  int main() {
    #pragma FAST hw:Price_FPGA
    Price_CPU(...);
  }
\end{lstlisting}


\section{Summary}

We have introduced the \FAST{} language one of the components required
as part of the proposed Aspect-oriented design flow. We have shown the
most important features of the \FAST{} language and how they map to
hardware components on the FPGA based dataflow engine. We have
highlighted the challenges of capturing these constructs with a simple
imperative language such as C and some possible solutions which we
investigate in  \Cref{sec:implementation}.

\Cref{table:feature-comparison1} contrasts the \FAST{} approach
proposed in this project with existing approaches in terms of syntax
and programming paradigm. An imperative, as opposed to functional
paradigm simplifies the language, making it more accessible to novice
users and integrates well with existing application source code. The
dataflow style of the \FAST{} specifications allows for an efficient
specification of designs that map well onto hardware accelerators such
as FPGA-based dataflow engines. The language supports integrated
hardware/software co-design with existing C applications, simplifying
the design exploration process by improving sharing of parameters and
by exposing a unified syntax to external design space exploration
tools (such as the LARA design space exploration flow).

Finally, \Cref{table:feature-comparison2} highlights the support for design
parametrisation and optimisation exploration strategies via the
automated aspect-oriented design flow as opposed to manual
transformations or meta-programming used by existing state-of-the art
compilers.


\begin{table}[!ht]
  \renewcommand{\arraystretch}{1.5}
  \centering
  \begin{tabularx}{\textwidth}{X | p{2.5cm} | p{3cm} | p{1.9cm} }
    \hline
    \bf{Language}                 & \bf{Syntax}              & \bf{Paradigm}               & \bf{Support}              \\
    \hline \hline
    \bf{Lucid}                    & Lucid                    & Functional                  & \multirow{3}{*}{Software} \\
    \cline{1-3}
    \bf{SISAL}                    & SISAL                    & Functional                  &                           \\
    \cline{1-3}
    \bf{Lustre}                   & Lustre                   & Synchronous                 &                           \\
    \bf{MaxCompiler}              & C99(SW) Java(HW)         & Imperative(SW) / Dataflow(HW) & \multirow{3}{*}{Combined} \\
    \bf{Streams-C} \bf{ImpulseC}\ & C99                      & Imperative(SW) / CSP(HW)      &                           \\
    \bf{\FAST{}}/\bf{LARA}        & C99(SW/HW) LARA(Aspects) & Imperative(SW) / Dataflow(HW) &                           \\
  \end{tabularx}
  \caption{Syntax, paradigm and support comparison of the \FAST{}/LARA approach and existing dataflow implementations.}
  \label{table:feature-comparison1}
\end{table}


\begin{table}[!ht]
  \renewcommand{\arraystretch}{1.5}
  \centering
  \begin{tabularx}{\textwidth}{ m{2.5cm} | X | X | p{2.5cm}}
    \hline
    \bf{Language}                  & \bf{Implementation}             & \bf{Design Parametrisation}                     & \bf{Optimisation Strategies}                                                                                                                                        \\
    \hline \hline
    \bf{Lucid}                     & \multirow{3}{*}{Multiprocessor} & \multirow{3}{3cm}{Manual Source Transformation} & \multirow{5}{3cm}{Manual Code Revision}                                                                                                                             \\
   \bf{SISAL}                      &                                 &                                                 &                                                                                                                                                                     \\
 \bf{Lustre}                      &                             &                              &                                                                            \\
    \bf{MaxCompiler}             & \multirow{6}{*}{CPU + FPGA} & Meta-programming             &                                                                            \\
\cline{1-1}\cline{2-3}
  \bf{Streams-C} \bf{ImpulseC}\ &                             & Compiler \newline Directives &                                                                            \\
\hline
  \bf{\FAST{}}/\bf{LARA}         &                             & \multicolumn{2}{p{7cm}}{Compiler Directives + \newline Automated Aspect-Directed Source Transformation} \\
  \end{tabularx}
  \caption{Implementation, parametrisation and optimisations comparison of the \FAST{}/LARA approach and existing dataflow implementations.}
  \label{table:feature-comparison2}
\end{table}
